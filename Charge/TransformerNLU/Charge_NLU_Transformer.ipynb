{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Charge_NLU_Transformer.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install keras-nlp"
   ],
   "metadata": {
    "id": "wYoKICSn-AQd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CfOh6lsF91pF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, LayerNormalization, Embedding, LSTM, GRU, Dense, Bidirectional, TimeDistributed, Input, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, LambdaCallback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "from keras_nlp.layers import PositionEmbedding, TokenAndPositionEmbedding\n",
    "from keras_nlp.layers import TransformerEncoder\n",
    "import slot_util as su\n",
    "import sentence_from_template as sft\n",
    "from tokenizer import Tokenizer\n",
    "from data_generator import DataGenerator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, LayerNormalization, Embedding, LSTM, GRU, Dense, Bidirectional, TimeDistributed, Input, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, LambdaCallback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "import random\n",
    "from keras_nlp.layers import PositionEmbedding, TokenAndPositionEmbedding\n",
    "from keras_nlp.layers import TransformerEncoder\n",
    "import slot_util as su\n",
    "import sentence_from_template as sft\n",
    "from tokenizer import Tokenizer\n",
    "from data_generator import DataGenerator\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TRAINING  PARAMETERS\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch=5000\n",
    "validation_steps=3000\n",
    "EPOCHS = 3\n",
    "\n",
    "# EMBEDDING  PARAMETERS\n",
    "NUM_WORDS = 250\n",
    "MAX_SEQ_LEN = 45\n",
    "EMBEDDING_DIM = 300\n",
    "VOCAB_SIZE = NUM_WORDS + 50\n",
    "\n",
    "\n",
    "# ENCODER  PARAMETERS\n",
    "INTERMEDIATE_DIM = 200\n",
    "NUM_HEADS = 2"
   ],
   "metadata": {
    "id": "J_F4O54rAaeb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TEST_SET = False\n",
    "SPLIT = 0.2\n",
    "with open(\"Charge.txt\", encoding='utf-8') as f:\n",
    "    templates = f.readlines()\n",
    "    templates = [line.strip().split(\" \") for line in templates]\n",
    "\n",
    "random.shuffle(templates)\n",
    "num_val_samples = int(SPLIT * len(templates))\n",
    "if TEST_SET:\n",
    "    num_train_samples = len(templates) - 2 * num_val_samples\n",
    "    train_templates = templates[:num_train_samples]\n",
    "    val_templates = templates[num_train_samples : num_train_samples + num_val_samples]\n",
    "    test_templates = templates[num_train_samples + num_val_samples :]\n",
    "else:\n",
    "    num_train_samples = len(templates) - num_val_samples\n",
    "    train_templates = templates[:num_train_samples]\n",
    "    val_templates = templates[num_train_samples : num_train_samples + num_val_samples]\n",
    "    test_templates = []\n",
    "\n",
    "\n",
    "print(f\"{len(templates)} total templates\")\n",
    "print(f\"{len(train_templates)} training templates\")\n",
    "print(f\"{len(val_templates)} validation templates\")\n",
    "print(f\"{len(test_templates)} test templates\")\n",
    "\n",
    "\n",
    "# Uncomment if you want to load saved splited templates\n",
    "with open(\"train_data.pickle\", \"rb\") as f:\n",
    "  train_templates = pickle.load(f)  \n",
    "with open(\"validation_data.pickle\", \"rb\") as f:\n",
    "  val_templates = pickle.load(f) \n",
    "if TEST_SET:\n",
    "  with open(\"test_data.pickle\", \"rb\") as f:\n",
    "    test_templates = pickle.load(f)  "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hC2yvaJDE37",
    "outputId": "79867125-b46a-4738-f3e4-cd45454b7190",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "67 total templates\n",
      "54 training templates\n",
      "13 validation templates\n",
      "0 test templates\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for t in val_templates[:2]:\n",
    "  print(t)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e8FtxUODPk1",
    "outputId": "54c77f4e-49c2-4df5-ccaf-fdcb3d60cb52",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['شارژ', '{amount}', '{unit}', '{charge_type}', '{operator}', '{for_{me}}', '{verb}']\n",
      "['{for}', '{device}', '{me}', '{from}', '{account}', '{bnumber}', 'شارژ', '{amount}', '{unit}', '{operator}', '{verb}']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "x_tokenizer = Tokenizer(num_words=NUM_WORDS, max_seq_len=MAX_SEQ_LEN,\n",
    "                        for_sentence=True, sos=False, eos=False)\n",
    "y_tokenizer = Tokenizer(num_words=NUM_WORDS, max_seq_len=MAX_SEQ_LEN,\n",
    "                        for_sentence=False, sos=False, eos=False)\n",
    "\n",
    "train_data_gen = DataGenerator(train_templates,\n",
    "                               x_tokenizer, y_tokenizer,\n",
    "                               BATCH_SIZE, steps_per_epoch,\n",
    "                               aug_percent=0.0, max_seq_len=MAX_SEQ_LEN)\n",
    "\n",
    "val_data_gen = DataGenerator(val_templates,\n",
    "                             x_tokenizer, y_tokenizer,\n",
    "                             BATCH_SIZE, validation_steps,\n",
    "                             aug_percent=0., max_seq_len=MAX_SEQ_LEN)\n",
    "if TEST_SET:\n",
    "    test_data_gen = DataGenerator(test_templates,\n",
    "                                  x_tokenizer, y_tokenizer,\n",
    "                                  BATCH_SIZE, validation_steps,\n",
    "                                  aug_percent=0., max_seq_len=MAX_SEQ_LEN)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NLFHB8oECX3",
    "outputId": "a4309724-5e12-495a-a088-a2919c5f5ff4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "all words length =  117\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Y_VOCAB_SIZE = len(y_tokenizer.word_to_index)"
   ],
   "metadata": {
    "id": "KiuWzLpMEF3g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inputs = Input(shape=(MAX_SEQ_LEN,))\n",
    "model = TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQ_LEN,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    ")(inputs)\n",
    "model = TransformerEncoder(\n",
    "    INTERMEDIATE_DIM,\n",
    "    NUM_HEADS,\n",
    "    dropout=0,\n",
    "    activation=\"relu\",)(model)\n",
    "model = TimeDistributed(Dense(150, activation='gelu'))(model)\n",
    "model = TimeDistributed(Dense(Y_VOCAB_SIZE, activation='softmax'))(model)\n",
    "model = Model(inputs, model)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[Precision(), Recall(), 'accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vV8l9KpBB32",
    "outputId": "dd2ff87c-175a-4cbc-cf4c-5d07678dd553",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 45)]              0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, 45, 300)          103500    \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_encoder (Transf  (None, 45, 300)          482900    \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 45, 150)          45150     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 45, 12)           1812      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 633,362\n",
      "Trainable params: 633,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "weight_path = \"{}_weights.best.hdf5\".format('nlu')\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, \n",
    "                                   verbose=1, mode='auto', min_delta=0.0001, cooldown=1, min_lr=0.0001)\n",
    "callbacks_list = [checkpoint, reduceLROnPlat]\n",
    "\n",
    "history = model.fit(train_data_gen, \n",
    "                    # batch_size = BATCH_SIZE, \n",
    "                    epochs = EPOCHS, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    validation_data = val_data_gen,\n",
    "                    callbacks = callbacks_list,)\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(weight_path)\n",
    "model.save('full_nlu_model.h5')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmkHCUxIBCBL",
    "outputId": "7c57cc6c-2cc6-425d-f37e-b5898fe9d79a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "5000/5000 [==============================] - ETA: 0s - loss: 0.0059 - precision: 0.9992 - recall: 0.9972 - accuracy: 0.9979"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "HLvta3fJBCEv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"x_tokenizer.pickle\", \"wb\") as f:\n",
    "  pickle.dump(x_tokenizer, f)\n",
    "with open(\"y_tokenizer.pickle\", \"wb\") as f:\n",
    "  pickle.dump(y_tokenizer, f)  \n",
    "\n",
    "with open(\"train_data.pickle\", \"wb\") as f:\n",
    "  pickle.dump(train_templates, f)  \n",
    "with open(\"validation_data.pickle\", \"wb\") as f:\n",
    "  pickle.dump(val_templates, f) \n",
    "if TEST_SET:\n",
    "  with open(\"test_data.pickle\", \"wb\") as f:\n",
    "    pickle.dump(test_templates, f)  "
   ],
   "metadata": {
    "id": "hNq7_1OoPpH_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "sentence = \"یه شارژ 50 تومنی واسم بخر\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9RxeVqoucAD",
    "outputId": "0cec0e05-355b-4f9e-ec01-6ff8effe9f07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "یه شارژ 50 تومنی واسم بخر\n",
      "['هیچ', 'هیچ', 'amount', 'unit', 'هیچ', 'هیچ']\n",
      "[('یه', 'هیچ'), ('شارژ', 'هیچ'), ('50', 'amount'), ('تومنی', 'unit'), ('واسم', 'هیچ'), ('بخر', 'هیچ')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"عشقم واسم یه شارژ 5 تومنی اینترنت ایرانسل میگیری برام فدات شم\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmTbX5y3uqgJ",
    "outputId": "cd99fdd1-6dad-402f-f805-279ce3e20352",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "عشقم واسم یه شارژ 5 تومنی اینترنت ایرانسل میگیری برام فدات شم\n",
      "['pnumber_post', 'هیچ', 'هیچ', 'هیچ', 'amount', 'unit', 'charge_type', 'operator', 'هیچ', 'هیچ', 'pnumber', 'هیچ']\n",
      "[('عشقم', 'pnumber_post'), ('واسم', 'هیچ'), ('یه', 'هیچ'), ('شارژ', 'هیچ'), ('5', 'amount'), ('تومنی', 'unit'), ('اینترنت', 'charge_type'), ('ایرانسل', 'operator'), ('میگیری', 'هیچ'), ('برام', 'هیچ'), ('فدات', 'pnumber'), ('شم', 'هیچ')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"جون دل شارژ 20 میلیون ریالی همراه اول از حساب 5859831022518434 واسه شماره 09173771786 بخر\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJDLm2JQuqi8",
    "outputId": "18bd5bd9-a57c-4139-d310-63aa201299f3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "جون دل شارژ 20 میلیون ریالی همراه اول از حساب 5859831022518434 واسه شماره 09173771786 بخر\n",
      "['هیچ', 'pnumber', 'هیچ', 'amount', 'unit', 'unit', 'operator', 'operator_post', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ', 'pnumber', 'هیچ']\n",
      "[('جون', 'هیچ'), ('دل', 'pnumber'), ('شارژ', 'هیچ'), ('20', 'amount'), ('میلیون', 'unit'), ('ریالی', 'unit'), ('همراه', 'operator'), ('اول', 'operator_post'), ('از', 'هیچ'), ('حساب', 'هیچ'), ('5859831022518434', 'bnumber'), ('واسه', 'هیچ'), ('شماره', 'هیچ'), ('09173771786', 'pnumber'), ('بخر', 'هیچ')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"آقا لطفا از حساب ملی من برای موبایل 22663377 شارژ رایتل شگفت انگیز 50 تومنی بخر\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-W_OMWcLuqlf",
    "outputId": "026d1ea0-a582-494c-e427-cee765361381",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "آقا لطفا از حساب ملی من برای موبایل 22663377 شارژ رایتل شگفت انگیز 50 تومنی بخر\n",
      "['pnumber_post', 'هیچ', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ', 'هیچ', 'pnumber', 'هیچ', 'operator', 'charge_type', 'charge_type_post', 'amount', 'unit', 'هیچ']\n",
      "[('آقا', 'pnumber_post'), ('لطفا', 'هیچ'), ('از', 'هیچ'), ('حساب', 'هیچ'), ('ملی', 'bnumber'), ('من', 'هیچ'), ('برای', 'هیچ'), ('موبایل', 'هیچ'), ('22663377', 'pnumber'), ('شارژ', 'هیچ'), ('رایتل', 'operator'), ('شگفت', 'charge_type'), ('انگیز', 'charge_type_post'), ('50', 'amount'), ('تومنی', 'unit'), ('بخر', 'هیچ')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"برای شماره سبا شارژ اینترنت 50 تومنی کارت به کارت کن از کارت 59595949549\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08rLGf9DucCe",
    "outputId": "04b6e5ce-5e43-452a-cc35-b593f45def03",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "برای شماره سبا شارژ اینترنت 50 تومنی کارت به کارت کن از کارت 59595949549\n",
      "['هیچ', 'هیچ', 'pnumber', 'هیچ', 'charge_type', 'amount', 'unit', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'bnumber']\n",
      "[('برای', 'هیچ'), ('شماره', 'هیچ'), ('سبا', 'pnumber'), ('شارژ', 'هیچ'), ('اینترنت', 'charge_type'), ('50', 'amount'), ('تومنی', 'unit'), ('کارت', 'هیچ'), ('به', 'هیچ'), ('کارت', 'هیچ'), ('کن', 'هیچ'), ('از', 'هیچ'), ('کارت', 'هیچ'), ('59595949549', 'bnumber')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"لطفا شارژ رایتل شگفت انگیز به مبلغ 50 تومن از حساب 5868 بگیر واسم برای شماره تلفن همراه آرمین خیاطی\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nK-Eq-5RucFM",
    "outputId": "cf1df8aa-6504-4056-fa6c-340f4fd2b4cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "لطفا شارژ رایتل شگفت انگیز به مبلغ 50 تومن از حساب 5868 بگیر واسم برای شماره تلفن همراه آرمین خیاطی\n",
      "['هیچ', 'هیچ', 'operator', 'charge_type', 'charge_type_post', 'هیچ', 'هیچ', 'amount', 'unit', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'pnumber', 'pnumber_post']\n",
      "[('لطفا', 'هیچ'), ('شارژ', 'هیچ'), ('رایتل', 'operator'), ('شگفت', 'charge_type'), ('انگیز', 'charge_type_post'), ('به', 'هیچ'), ('مبلغ', 'هیچ'), ('50', 'amount'), ('تومن', 'unit'), ('از', 'هیچ'), ('حساب', 'هیچ'), ('5868', 'bnumber'), ('بگیر', 'هیچ'), ('واسم', 'هیچ'), ('برای', 'هیچ'), ('شماره', 'هیچ'), ('تلفن', 'هیچ'), ('همراه', 'هیچ'), ('آرمین', 'pnumber'), ('خیاطی', 'pnumber_post')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"لطفا شارژ رایتل شگفت انگیز به مبلغ 50 تومن از حساب 5868 بگیر واسم برای شماره تلفن همراه آرمین خیاطی سریع فقط باشه مرسی\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbvQzWnk5g4X",
    "outputId": "6beb9057-d676-4424-cbb2-b1c96677795b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "لطفا شارژ رایتل شگفت انگیز به مبلغ 50 تومن از حساب 5868 بگیر واسم برای شماره تلفن همراه آرمین خیاطی سریع فقط باشه مرسی\n",
      "['هیچ', 'هیچ', 'operator', 'charge_type', 'charge_type_post', 'هیچ', 'هیچ', 'amount', 'unit', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'pnumber', 'pnumber_post', 'pnumber_post', 'pnumber_post', 'pnumber_post', 'pnumber_post']\n",
      "[('لطفا', 'هیچ'), ('شارژ', 'هیچ'), ('رایتل', 'operator'), ('شگفت', 'charge_type'), ('انگیز', 'charge_type_post'), ('به', 'هیچ'), ('مبلغ', 'هیچ'), ('50', 'amount'), ('تومن', 'unit'), ('از', 'هیچ'), ('حساب', 'هیچ'), ('5868', 'bnumber'), ('بگیر', 'هیچ'), ('واسم', 'هیچ'), ('برای', 'هیچ'), ('شماره', 'هیچ'), ('تلفن', 'هیچ'), ('همراه', 'هیچ'), ('آرمین', 'pnumber'), ('خیاطی', 'pnumber_post'), ('سریع', 'pnumber_post'), ('فقط', 'pnumber_post'), ('باشه', 'pnumber_post'), ('مرسی', 'pnumber_post')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"لطفا شارژ رایتل شگفت انگیز به مبلغ 50 تومن برای شماره تلفن همراه آرمین خیاطی سریع فقط باشه مرسی از حساب 5868 بگیر واسم\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFsEvUCN5vv0",
    "outputId": "d2de6e1a-b692-44da-da89-f055539a51e4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "لطفا شارژ رایتل شگفت انگیز به مبلغ 50 تومن برای شماره تلفن همراه آرمین خیاطی سریع فقط باشه مرسی از حساب 5868 بگیر واسم\n",
      "['هیچ', 'هیچ', 'operator', 'charge_type', 'charge_type_post', 'هیچ', 'هیچ', 'amount', 'unit', 'هیچ', 'هیچ', 'هیچ', 'هیچ', 'pnumber', 'pnumber_post', 'pnumber_post', 'pnumber_post', 'pnumber_post', 'pnumber_post', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ']\n",
      "[('لطفا', 'هیچ'), ('شارژ', 'هیچ'), ('رایتل', 'operator'), ('شگفت', 'charge_type'), ('انگیز', 'charge_type_post'), ('به', 'هیچ'), ('مبلغ', 'هیچ'), ('50', 'amount'), ('تومن', 'unit'), ('برای', 'هیچ'), ('شماره', 'هیچ'), ('تلفن', 'هیچ'), ('همراه', 'هیچ'), ('آرمین', 'pnumber'), ('خیاطی', 'pnumber_post'), ('سریع', 'pnumber_post'), ('فقط', 'pnumber_post'), ('باشه', 'pnumber_post'), ('مرسی', 'pnumber_post'), ('از', 'هیچ'), ('حساب', 'هیچ'), ('5868', 'bnumber'), ('بگیر', 'هیچ'), ('واسم', 'هیچ')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"شارژ شگفت انگیز ایرنسل 50 هزار تومنی\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiA8yhZvPMdq",
    "outputId": "60fd6893-9dda-4cdf-e69a-8731da2b7861",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "شارژ شگفت انگیز ایرنسل 50 هزار تومنی\n",
      "['هیچ', 'charge_type', 'charge_type_post', 'amount', 'amount', 'unit', 'unit']\n",
      "[('شارژ', 'هیچ'), ('شگفت', 'charge_type'), ('انگیز', 'charge_type_post'), ('ایرنسل', 'amount'), ('50', 'amount'), ('هزار', 'unit'), ('تومنی', 'unit')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"برای شماره 0918383838 از حساب 9494949 شارژ 90 تومنی همراه اول کارت به کارت کن\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfbhDmEgRqBs",
    "outputId": "15e22dd1-ecc3-410d-8367-f1b5986d7508",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "برای شماره 0918383838 از حساب 9494949 شارژ 90 تومنی همراه اول کارت به کارت کن\n",
      "['هیچ', 'هیچ', 'pnumber', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'amount', 'unit', 'operator', 'operator_post', 'هیچ', 'هیچ', 'هیچ', 'هیچ']\n",
      "[('برای', 'هیچ'), ('شماره', 'هیچ'), ('0918383838', 'pnumber'), ('از', 'هیچ'), ('حساب', 'هیچ'), ('9494949', 'bnumber'), ('شارژ', 'هیچ'), ('90', 'amount'), ('تومنی', 'unit'), ('همراه', 'operator'), ('اول', 'operator_post'), ('کارت', 'هیچ'), ('به', 'هیچ'), ('کارت', 'هیچ'), ('کن', 'هیچ')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"واسم شارژ همراه اول 50 تومنی بخر از کارت 84949494 برای خط سبا\"\n",
    "input_seq = x_tokenizer.words_to_seq(sentence.split(\" \"))\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(sentence.split(\" \"), slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxFRi9iGSBht",
    "outputId": "1e2a75ff-fee1-4e03-9a13-952a215beb96",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "واسم شارژ همراه اول 50 تومنی بخر از کارت 84949494 برای خط سبا\n",
      "['هیچ', 'هیچ', 'operator', 'operator_post', 'amount', 'unit', 'هیچ', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ', 'pnumber']\n",
      "[('واسم', 'هیچ'), ('شارژ', 'هیچ'), ('همراه', 'operator'), ('اول', 'operator_post'), ('50', 'amount'), ('تومنی', 'unit'), ('بخر', 'هیچ'), ('از', 'هیچ'), ('کارت', 'هیچ'), ('84949494', 'bnumber'), ('برای', 'هیچ'), ('خط', 'هیچ'), ('سبا', 'pnumber')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = \"واسم شارژ همراه اول 50 تومنی بخر از کارت     84949494 برای خط سبا\"\n",
    "inp =sentence.strip().split(\" \")\n",
    "inp = [w for w in inp if w != '']\n",
    "input_seq = x_tokenizer.words_to_seq(inp)\n",
    "prediction = model.predict([input_seq])\n",
    "slots = [np.argmax(x) for x in prediction[0][:]]\n",
    "slots = y_tokenizer.seq_to_words(slots)\n",
    "slots = [s if s != 'OOV' else 'هیچ' for s in slots  ]\n",
    "print(sentence)\n",
    "print(slots)\n",
    "print(list(zip(inp, slots)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjGZgQ0uTnPR",
    "outputId": "818ef066-4c6b-46d5-9ca8-5acac82d5712",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "واسم شارژ همراه اول 50 تومنی بخر از کارت     84949494 برای خط سبا\n",
      "['هیچ', 'هیچ', 'operator', 'operator_post', 'amount', 'unit', 'هیچ', 'هیچ', 'هیچ', 'bnumber', 'هیچ', 'هیچ', 'pnumber']\n",
      "[('واسم', 'هیچ'), ('شارژ', 'هیچ'), ('همراه', 'operator'), ('اول', 'operator_post'), ('50', 'amount'), ('تومنی', 'unit'), ('بخر', 'هیچ'), ('از', 'هیچ'), ('کارت', 'هیچ'), ('84949494', 'bnumber'), ('برای', 'هیچ'), ('خط', 'هیچ'), ('سبا', 'pnumber')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "fjcrVanBEcSI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model.load_weights(weight_path)\n",
    "# model.save('full_nlu_model.h5')"
   ],
   "metadata": {
    "id": "XtsWk4J_EcU6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotmodel(history,name):\n",
    "    # precision = history.history['precision_2']\n",
    "    # val_precision = history.history['val_precision_2']\n",
    "    # recall = history.history['recall_2']\n",
    "    # val_recall = history.history['val_recall_2']\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    lrs = history.history['lr']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,acc)#mooth_curve(acc))\n",
    "    plt.plot(epochs,val_acc)#smooth_curve(val_acc))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    plt.savefig('acc_'+name+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs, loss)#smooth_curve(loss))\n",
    "    plt.plot(epochs,val_loss)#smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.savefig('loss_'+name+'.png')\n",
    "    \n",
    "    plt.figure(3)\n",
    "    plt.plot(epochs, lrs)#,smooth_curve(lrs))\n",
    "    plt.ylabel('lr')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['lr'], loc='upper right')\n",
    "    plt.savefig('lr_'+name+'.png')\n",
    "\n",
    "    # plt.figure(4)                  \n",
    "    # plt.plot(epochs,precision)#mooth_curve(acc))\n",
    "    # plt.plot(epochs,val_precision)#smooth_curve(val_acc))\n",
    "    # plt.ylabel('precision')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train_precision', 'val_precision'], loc='upper left')\n",
    "    # plt.savefig('precision_'+name+'.png')\n",
    "\n",
    "    # plt.figure(5)                  \n",
    "    # plt.plot(epochs,recall)#mooth_curve(acc))\n",
    "    # plt.plot(epochs,val_recall)#smooth_curve(val_acc))\n",
    "    # plt.ylabel('recall')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train_recall', 'val_recall'], loc='upper left')\n",
    "    # plt.savefig('recall_'+name+'.png')\n",
    "plotmodel(history,'history')\n"
   ],
   "metadata": {
    "id": "hVAbI7JfEcX1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}